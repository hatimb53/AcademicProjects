{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow Up Questions Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from autocorrect import spell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>followUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Are you a self-motivator?</td>\n",
       "      <td>Absolutely. For me, internal motivation works ...</td>\n",
       "      <td>Awesome. How would you spread motivation to ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What matters to you more - job satisfaction or...</td>\n",
       "      <td>According to me, job satisfaction covers all -...</td>\n",
       "      <td>Are you ready to work in a company who offers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What matters to you more - job satisfaction or...</td>\n",
       "      <td>According to me, job satisfaction covers all -...</td>\n",
       "      <td>If you are not able to adjust with your teamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Have you worked with someone unprofessional, h...</td>\n",
       "      <td>During my B-Tech final semester internship, I ...</td>\n",
       "      <td>Do you think not showing the displeasure is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Have you worked with someone unprofessional, h...</td>\n",
       "      <td>During my B-Tech final semester internship, I ...</td>\n",
       "      <td>If the same situation arises now, will you tak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0                          Are you a self-motivator?   \n",
       "1           1  What matters to you more - job satisfaction or...   \n",
       "2           2  What matters to you more - job satisfaction or...   \n",
       "3           3  Have you worked with someone unprofessional, h...   \n",
       "4           4  Have you worked with someone unprofessional, h...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Absolutely. For me, internal motivation works ...   \n",
       "1  According to me, job satisfaction covers all -...   \n",
       "2  According to me, job satisfaction covers all -...   \n",
       "3  During my B-Tech final semester internship, I ...   \n",
       "4  During my B-Tech final semester internship, I ...   \n",
       "\n",
       "                                            followUp  \n",
       "0  Awesome. How would you spread motivation to ot...  \n",
       "1  Are you ready to work in a company who offers ...  \n",
       "2  If you are not able to adjust with your teamma...  \n",
       "3  Do you think not showing the displeasure is th...  \n",
       "4  If the same situation arises now, will you tak...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"./followMLdata.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "que=data['question']\n",
    "ans=data['answer']\n",
    "flw=data['followUp']\n",
    "stop_words = set(stopwords.words('english')) \n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell Correction, Removing punctuation, Tokenizing and making word_to_vec dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector={}\n",
    "for i in que.tolist():\n",
    "    s=regex.sub(' ',i)\n",
    "    words=word_tokenize(s)\n",
    "    for word_tokens in words:\n",
    "        w=word_tokens.lower()\n",
    "        w=spell(w)\n",
    "        word_vector[w]=[]\n",
    "\n",
    "for i in ans.tolist():\n",
    "    s=regex.sub(' ',i)\n",
    "    words=word_tokenize(s)\n",
    "    for word_tokens in words:\n",
    "        w=word_tokens.lower()\n",
    "        w=spell(w)\n",
    "        word_vector[w]=[]\n",
    "\n",
    "for i in flw.tolist():\n",
    "    s=regex.sub(' ',i)\n",
    "    words=word_tokenize(s)\n",
    "    for word_tokens in words:\n",
    "        w=word_tokens.lower()\n",
    "        w=spell(w)\n",
    "        word_vector[w]=[]\n",
    "    \n",
    "  \n",
    "    #print(filtered_sentence)\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining maximum number sentences and words in each row in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxqsen  4\n",
      "maxrsen  21\n",
      "maxqword  33\n",
      "maxrword  79\n",
      "maxfword  45\n"
     ]
    }
   ],
   "source": [
    "mx=0\n",
    "for i in que:\n",
    "    l=len(i.split('?'))\n",
    "    if mx<l:\n",
    "        mx=l\n",
    "print(\"maxqsen \",mx)\n",
    "\n",
    "mx=0\n",
    "for i in ans:\n",
    "    l=len(i.split('.'))\n",
    "    if mx<l:\n",
    "        mx=l\n",
    "print(\"maxrsen \",mx)\n",
    "mx=0\n",
    "for i in que:\n",
    "    l=i.split('?')\n",
    "    for j in l:\n",
    "        w=len(word_tokenize(j))\n",
    "        if mx<w:\n",
    "            mx=w\n",
    "print(\"maxqword \",mx)\n",
    "mx=0\n",
    "for i in ans:\n",
    "    l=i.split('.')\n",
    "    for j in l:\n",
    "        w=len(word_tokenize(j))\n",
    "        if mx<w:\n",
    "            mx=w\n",
    "print(\"maxrword \",mx)\n",
    "        \n",
    "    \n",
    "mx=0\n",
    "for i in flw:\n",
    "    l=len(word_tokenize(i))\n",
    "    if mx<l:\n",
    "        mx=l\n",
    "print(\"maxfword \",mx)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxqsen=5\n",
    "maxrsen=25\n",
    "maxqword=50\n",
    "maxrword=100\n",
    "maxfword=50\n",
    "\n",
    "emb=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading glove embedding and assigning to word dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist  0\n",
      "exist  949\n",
      "exist  1779\n",
      "exist  2619\n",
      "exist  2620\n",
      "exist  3349\n",
      "exist  3350\n",
      "400000   3509\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('./glove.6B/glove.6B.50d.txt','r',encoding=\"utf8\") as file: \n",
    "    count=0\n",
    "    cnt=0\n",
    "    for index, line in enumerate(file): \n",
    "        #print(line)\n",
    "        values = line.split()\n",
    "        word=values[0]\n",
    "        word_weights = np.asarray(values[1:], dtype=np.float32)\n",
    "        if word in word_vector.keys():\n",
    "            print(\"exist \",cnt)\n",
    "            cnt=cnt+1\n",
    "            word_vector[word]= word_weights\n",
    "            \n",
    "        #print(count,\" \",word)\n",
    "        count=count+1\n",
    "        #print(word)\n",
    "        #print(word_weights)\n",
    "        \n",
    "    print(count,\" \",cnt)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding words not available in glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lederer\n",
      "algorithicm\n",
      "concentratedly\n",
      "unprossional\n",
      "batchmates\n",
      "Bangalore\n",
      "Benz\n",
      "youhave\n",
      "weighage\n",
      "IOT\n",
      "Hackathorn\n",
      "Hyderabad\n",
      "schoolsindia\n",
      "definedly\n",
      "obsessivecompulsive\n",
      "thuses\n",
      "unorder\n",
      "Kalyan\n",
      "AIEEE\n",
      "GitHub\n",
      "intellective\n",
      "dubaara\n",
      "comfortableness\n",
      "Bollywood\n",
      "JavaScript\n",
      "localstorage\n",
      "calculative\n",
      "incase\n",
      "IP\n",
      "direr\n",
      "Alduino\n",
      "APJ\n",
      "FIFA\n",
      "Chennai\n",
      "usedly\n",
      "Uno\n",
      "Sudoku\n",
      "sahyog\n",
      "sagittarian\n",
      "iiitb\n",
      "TCS\n",
      "reproval\n",
      "Stallone\n",
      "Woking\n",
      "schwarztneger\n",
      "persued\n",
      "uncharge\n",
      "linkedit\n",
      "iitjee\n",
      "retrospected\n",
      "chitchatting\n",
      "Microsoft\n",
      "Abdul\n",
      "YouTube\n",
      "jokul\n",
      "Mercedes\n",
      "remotivation\n",
      "youve\n",
      "throwball\n",
      "indited\n",
      "criterial\n",
      "MTech\n",
      "Ve\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "mispell=[]\n",
    "cnt=0\n",
    "for i in word_vector.keys():\n",
    "    try:\n",
    "        a=word_vector[i].shape\n",
    "    except:\n",
    "        print(i)\n",
    "        mispell.append(i)\n",
    "        cnt=cnt+1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing inputs and labels for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes\n",
      "questions  (1086, 5, 50, 50)\n",
      "responses  (1086, 25, 100, 50)\n",
      "responses length  (1086, 25)\n",
      "followup questions  (1086, 50, 50)\n",
      "followup questions length  (1086,)\n"
     ]
    }
   ],
   "source": [
    "# 4,21,33,79,45\n",
    "print(\"shapes\")\n",
    "qs=[]\n",
    "for i in que.tolist():\n",
    "    temp=i.split('?')\n",
    "    qn=[]\n",
    "    for j in temp:\n",
    "        s=regex.sub(' ',j)\n",
    "        words=word_tokenize(s)\n",
    "        qw=[]\n",
    "        for word_tokens in words:\n",
    "            w=word_tokens.lower()\n",
    "            w=spell(w)\n",
    "\n",
    "            if w in mispell:\n",
    "                qw.append(word_vector['a'].tolist())\n",
    "            else:\n",
    "                qw.append(word_vector[w].tolist())\n",
    "            \n",
    "        b=maxqword-len(words)\n",
    "        for t in range(b):\n",
    "            qw.append(np.zeros((emb,)).tolist())\n",
    "        \n",
    "        qn.append(qw)\n",
    "        \n",
    "    b=maxqsen-len(temp) \n",
    "    for t in range(b):\n",
    "        qw=[]\n",
    "        for tt in range(maxqword):\n",
    "            qw.append(np.zeros((emb,)).tolist())\n",
    "        qn.append(qw)\n",
    "        \n",
    "            \n",
    "        \n",
    "    qs.append(qn)\n",
    "\n",
    "qs=np.array(qs)\n",
    "print(\"questions \",qs.shape)\n",
    "    \n",
    "# 4,21,33,79,45\n",
    "\n",
    "rs=[]\n",
    "rsqlen=[]\n",
    "for i in ans.tolist():\n",
    "    temp=i.split('.')\n",
    "    rn=[]\n",
    "    rsn=[]\n",
    "    for j in temp:\n",
    "        s=regex.sub(' ',j)\n",
    "        words=word_tokenize(s)\n",
    "        rw=[]\n",
    "        for word_tokens in words:\n",
    "            w=word_tokens.lower()\n",
    "            w=spell(w)\n",
    "\n",
    "            if w in mispell:\n",
    "                rw.append(word_vector['a'].tolist())\n",
    "            else:\n",
    "                rw.append(word_vector[w].tolist())\n",
    "            \n",
    "        b=maxrword-len(words)\n",
    "        for t in range(b):\n",
    "            rw.append(np.zeros((emb,)).tolist())\n",
    "        \n",
    "        rn.append(rw)\n",
    "        rsn.append(b)\n",
    "        \n",
    "    b=maxrsen-len(temp) \n",
    "    for t in range(b):\n",
    "        rw=[]\n",
    "        for tt in range(maxrword):\n",
    "            rw.append(np.zeros((emb,)).tolist())\n",
    "        rn.append(rw)\n",
    "        rsn.append(0)\n",
    "            \n",
    "    rsqlen.append(rsn)   \n",
    "    rs.append(rn)\n",
    "\n",
    "rs=np.array(rs)\n",
    "rsqlen=np.array(rsqlen)\n",
    "print(\"responses \",rs.shape)\n",
    "print(\"responses length \",rsqlen.shape)\n",
    "\n",
    "       \n",
    "fs=[]\n",
    "fsqlen=[]\n",
    "\n",
    "for i in flw.tolist():\n",
    "    \n",
    "    s=regex.sub(' ',i)\n",
    "    words=word_tokenize(s)\n",
    "    fw=[]\n",
    "    for word_tokens in words:\n",
    "        w=word_tokens.lower()\n",
    "        w=spell(w)\n",
    "\n",
    "        if w in mispell:\n",
    "            fw.append(word_vector['a'].tolist())\n",
    "        else:\n",
    "            fw.append(word_vector[w].tolist())\n",
    "\n",
    "    b=maxfword-len(words)\n",
    "    for t in range(b):\n",
    "        fw.append(np.zeros((emb,)).tolist())\n",
    "   \n",
    "    fs.append(fw)\n",
    "    fsqlen.append(b)\n",
    "\n",
    "fs=np.array(fs)\n",
    "fsqlen=np.array(fsqlen)\n",
    "print(\"followup questions \",fs.shape)\n",
    "print(\"followup questions length \",fsqlen.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making tensorflow computation graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN and Topk values in vector are use for making sentence representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"CNN/Reshape:0\", shape=(?, 50, 50), dtype=float32)\n",
      "Tensor(\"CNN/conv1d/BiasAdd:0\", shape=(?, 48, 1), dtype=float32)\n",
      "ge\n",
      "Tensor(\"CNN/Reshape_1:0\", shape=(?, ?), dtype=float32)\n",
      "TopKV2(values=<tf.Tensor 'CNN/TopKV2:0' shape=(?, 20) dtype=float32>, indices=<tf.Tensor 'CNN/TopKV2:1' shape=(?, 20) dtype=int32>)\n",
      "Tensor(\"CNN/Reshape_2:0\", shape=(?, 5, 20), dtype=float32)\n",
      "Tensor(\"CNN/Reshape_3:0\", shape=(?, 100, 50), dtype=float32)\n",
      "Tensor(\"CNN/conv1d_1/BiasAdd:0\", shape=(?, 98, 1), dtype=float32)\n",
      "Tensor(\"CNN/Reshape_4:0\", shape=(?, ?), dtype=float32)\n",
      "TopKV2(values=<tf.Tensor 'CNN/TopKV2_1:0' shape=(?, 20) dtype=float32>, indices=<tf.Tensor 'CNN/TopKV2_1:1' shape=(?, 20) dtype=int32>)\n",
      "Tensor(\"CNN/Reshape_5:0\", shape=(?, 25, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "batch_size=1086\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    dtypei=tf.int32\n",
    "    dtypef=tf.float32\n",
    "    src_seq_length=tf.placeholder(dtypei,[None,maxrsen])\n",
    "    trg_seq_length=tf.placeholder(dtypei,[None,])\n",
    "\n",
    "    ns=20\n",
    "    a=5\n",
    "    dtypef=tf.float32\n",
    "    dtypei=tf.int32\n",
    "    inputsq=tf.placeholder(dtypef,[None,maxqsen,maxqword,emb])\n",
    "    inputsr=tf.placeholder(dtypef,[None,maxrsen,maxrword,emb])\n",
    "    \n",
    "    with tf.variable_scope(\"CNN\"):\n",
    "    \n",
    "        batch,_,_,_=tf.unstack(tf.shape(inputsq))\n",
    "        qss=tf.reshape(inputsq,(batch*maxqsen,maxqword,emb))\n",
    "        print(qss)\n",
    "        conv1d=tf.layers.conv1d(qss,1,3)\n",
    "        print(conv1d)\n",
    "        b1,dim,_=tf.unstack(tf.shape(conv1d))\n",
    "        print(\"ge\")\n",
    "        val=tf.reshape(conv1d,(b1,dim))\n",
    "        print(val)\n",
    "        topk=tf.nn.top_k(val,ns)\n",
    "        print(topk)\n",
    "\n",
    "\n",
    "        aa=tf.reshape(topk.values,(batch,maxqsen,ns))\n",
    "        print(aa)\n",
    "\n",
    "\n",
    "\n",
    "        rss=tf.reshape(inputsr,(batch*maxrsen,maxrword,emb))\n",
    "\n",
    "\n",
    "        print(rss)\n",
    "        conv1d=tf.layers.conv1d(rss,1,3)\n",
    "        print(conv1d)\n",
    "        b2,dim,_=tf.unstack(tf.shape(conv1d))\n",
    "\n",
    "        val=tf.reshape(conv1d,(b2,dim))\n",
    "        print(val)\n",
    "        topk=tf.nn.top_k(val,ns)\n",
    "        print(topk)\n",
    "\n",
    "        bb=tf.reshape(topk.values,(batch,maxrsen,ns))\n",
    "        print(bb)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding score of each questions and response pair by following equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attention.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"NTN/Mul:0\", shape=(5, 25, ?, 20), dtype=float32)\n",
      "Tensor(\"NTN/Mul_1:0\", shape=(5, 25, ?, 20), dtype=float32)\n",
      "Tensor(\"NTN/Reshape_6:0\", shape=(5, 25, ?, 5), dtype=float32)\n",
      "res Tensor(\"NTN/Reshape_9:0\", shape=(125, ?), dtype=float32)\n",
      "Tensor(\"NTN/Cast:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"NTN/GatherNd:0\", shape=(?,), dtype=int32) Tensor(\"Placeholder_3:0\", shape=(?, 25, 100, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    \n",
    "    with tf.variable_scope(\"NTN\"):\n",
    "        M= tf.Variable(tf.truncated_normal(shape=(ns,ns,a),dtype=dtypef))\n",
    "        V=tf.Variable(tf.truncated_normal(shape=(2*ns,a),dtype=dtypef))\n",
    "        U=tf.Variable(tf.truncated_normal(shape=(a,),dtype=dtypef))\n",
    "        b=tf.Variable(tf.zeros(shape=(a,),dtype=dtypef))\n",
    "\n",
    "        tmp1=tf.multiply(tf.reshape(tf.transpose(aa,(1,0,2)),(maxqsen,1,batch,ns)),tf.ones(shape=(maxqsen,maxrsen,batch,ns),dtype=dtypef))\n",
    "        print(tmp1)\n",
    "        tmp2=tf.multiply(tf.reshape(tf.transpose(bb,(1,0,2)),(1,maxrsen,batch,ns)),tf.ones(shape=(maxqsen,maxrsen,batch,ns),dtype=dtypef))\n",
    "        print(tmp2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ft=tf.tensordot(tmp1,tf.reshape(M,(1,ns,ns,a)),axes=[[3],[1]])\n",
    "        ft=tf.reshape(ft,(maxqsen,maxrsen,batch,ns,a))\n",
    "        ft=tf.multiply(ft,tf.reshape(tmp2,(maxqsen,maxrsen,batch,ns,1)))\n",
    "        ft=tf.reduce_sum(ft,axis=3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        st=tf.reshape(tf.tensordot(tf.concat((tmp1,tmp2),axis=3),tf.reshape(V,(1,1,2*ns,a)),axes=[[3],[2]]),(maxqsen,maxrsen,batch,a))\n",
    "        print(st)\n",
    "\n",
    "\n",
    "\n",
    "        res=tf.reshape(tf.tensordot(tf.nn.tanh(tf.add(tf.add(ft,st),tf.reshape(b,(1,1,1,a)))),tf.reshape(U,(1,1,1,a)),axes=[[3],[3]]),(maxqsen*maxrsen,batch))\n",
    "\n",
    "\n",
    "        print(\"res\",res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ind=tf.cast(tf.mod(tf.argmax(res,axis=0),maxrsen),dtypei)\n",
    "        print(ind)\n",
    "\n",
    "        row_indices = tf.range(batch,dtype=dtypei)\n",
    "\n",
    "        indices = tf.transpose([row_indices, ind])\n",
    "\n",
    "\n",
    "        srclen=tf.cast(tf.gather_nd(src_seq_length,indices),dtypei)\n",
    "        print(srclen,inputsr)\n",
    "\n",
    "\n",
    "\n",
    "        responses=tf.cast(tf.gather_nd(inputsr, indices),dtypef)\n",
    "    \n",
    "    #sess=tf.Session()\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #indic,i=sess.run([ind,indices],{inputsq:qs[0:5],inputsr:rs[0:5],src_seq_length:rsqlen[0:5],trg_seq_length:fsqlen[0:5]})\n",
    "    \n",
    "    #print(indic,i)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq to Seq model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001AA4C83CEB8>\n",
      "context_vector Tensor(\"seq_to_seq/encoder/rnn/transpose_1:0\", shape=(?, 100, 30), dtype=float32)\n",
      "emit None\n",
      "elements_finished Tensor(\"seq_to_seq/decoder/rnn/GreaterEqual:0\", shape=(?,), dtype=bool)\n",
      "1086\n",
      "Tensor(\"Placeholder_5:0\", shape=(?, 80), dtype=float32)\n",
      "cell_output Tensor(\"seq_to_seq/decoder/rnn/while/lstm_cell/mul_2:0\", shape=(?, 30), dtype=float32)\n",
      "1086\n",
      "ft Tensor(\"seq_to_seq/decoder/rnn/while/attention/Sum:0\", shape=(?, 100, 5), dtype=float32)\n",
      "st Tensor(\"seq_to_seq/decoder/rnn/while/attention/concat:0\", shape=(?, 100, 60), dtype=float32) Tensor(\"seq_to_seq/decoder/rnn/while/attention/Reshape_2:0\", shape=(60, 5, 1), dtype=float32)\n",
      "Tensor(\"seq_to_seq/decoder/rnn/while/attention/Tensordot_1:0\", shape=(?, 100, 5, 1), dtype=float32)\n",
      "st Tensor(\"seq_to_seq/decoder/rnn/while/attention/Reshape_5:0\", shape=(?, 100, 5), dtype=float32)\n",
      "tt Tensor(\"seq_to_seq/decoder/rnn/while/attention/Reshape_6:0\", shape=(1, 1, 5), dtype=float32)\n",
      "a Tensor(\"seq_to_seq/decoder/rnn/while/attention/Softmax:0\", shape=(?, 100), dtype=float32)\n",
      "alpha Tensor(\"seq_to_seq/decoder/rnn/while/attention/Reshape_8:0\", shape=(?, 100, 1), dtype=float32)\n",
      "inp Tensor(\"seq_to_seq/decoder/rnn/while/concat:0\", shape=(?, 80), dtype=float32)\n",
      "emit Tensor(\"seq_to_seq/decoder/rnn/while/lstm_cell/mul_2:0\", shape=(?, 30), dtype=float32)\n",
      "elements_finished Tensor(\"seq_to_seq/decoder/rnn/while/GreaterEqual:0\", shape=(?,), dtype=bool)\n",
      "1086\n",
      "Tensor(\"seq_to_seq/decoder/rnn/while/concat:0\", shape=(?, 80), dtype=float32)\n",
      "decoder (<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000001AA4CB542B0>, LSTMStateTuple(c=<tf.Tensor 'seq_to_seq/decoder/rnn/while/Exit_4:0' shape=(?, 30) dtype=float32>, h=<tf.Tensor 'seq_to_seq/decoder/rnn/while/Exit_5:0' shape=(?, 30) dtype=float32>), None)\n",
      "outputs= Tensor(\"seq_to_seq/decoder/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?, ?, 30), dtype=float32)\n",
      "temp Tensor(\"seq_to_seq/decoder/Sigmoid:0\", shape=(?, 50), dtype=float32)\n",
      "labels= Tensor(\"Placeholder_4:0\", shape=(?, 50, 50), dtype=float32)\n",
      "predicted= Tensor(\"seq_to_seq/decoder/transpose:0\", shape=(?, ?, 50), dtype=float32)\n",
      "shape Tensor(\"seq_to_seq/decoder/Shape_2:0\", shape=(3,), dtype=int32)\n",
      "labels= Tensor(\"seq_to_seq/decoder/Slice:0\", shape=(?, ?, ?), dtype=float32)\n",
      "Tensor(\"loss/mean_squared_error/value:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "src_emb_size=50\n",
    "trg_emb_size=50\n",
    "\n",
    "num_units=30\n",
    "attention_a=5\n",
    "#src_seq_len=30\n",
    "#trg_seq_len=30\n",
    "epochs=1\n",
    "max_time=30\n",
    "\n",
    "dtypei=tf.int32\n",
    "dtypef=tf.float32\n",
    "\n",
    "\n",
    "\n",
    "with g.as_default():\n",
    "\n",
    "    labels=tf.placeholder(dtypef,[None,maxfword,trg_emb_size])\n",
    "\n",
    "    #src_seq_length=tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "    initialize=tf.placeholder(dtypef,[None,trg_emb_size+num_units])\n",
    "\n",
    "\n",
    "    \n",
    "    with tf.variable_scope(\"seq_to_seq\"):\n",
    "\n",
    "        \n",
    "        Ua=tf.Variable(tf.truncated_normal(shape=(attention_a,),dtype=dtypef))\n",
    "        ba=tf.Variable(tf.zeros(shape=(attention_a,),dtype=dtypef))\n",
    "        Va=tf.Variable(tf.truncated_normal(shape=(2*num_units,attention_a),dtype=dtypef))\n",
    "        Ma=tf.Variable(tf.truncated_normal(shape=(num_units,num_units,attention_a),dtype=dtypef))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #encoder_word_embeddings = tf.Variable(tf.truncated_normal(shape=(src_vocab_size,src_emb_size)))\n",
    "    #embedded_word_ids = tf.nn.embedding_lookup(encoder_word_embeddings, inputs)\n",
    "\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "\n",
    "\n",
    "            encoder_lstm_cell=tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "            print(encoder_lstm_cell)\n",
    "\n",
    "            encoder_lstm_net=tf.nn.dynamic_rnn(inputs=responses,cell=encoder_lstm_cell,dtype=dtypef,sequence_length=srclen)\n",
    "\n",
    "            context_vector,encoder_final_state=encoder_lstm_net\n",
    "\n",
    "            #context_vector=tf.multiply(tf.ones((1,max_time,num_units)),context_vector)\n",
    "            print(\"context_vector\",context_vector)\n",
    "\n",
    "            lab=2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #batchSize=tf.unstack(tf.shape(inputs))[0]\n",
    "        #print(batchSize)\n",
    "        #batchSize=tf.constant(batchSize)\n",
    "\n",
    "        dense_w=tf.Variable(tf.truncated_normal(shape=(num_units,trg_emb_size)))\n",
    "        dense_b=tf.Variable(tf.zeros(shape=(trg_emb_size,)))\n",
    "\n",
    "        def loop_fn(time, cell_output, cell_state, loop_state):\n",
    "\n",
    "\n",
    "\n",
    "              # == None for time == 0\n",
    "            #print(\"time=\",time)\n",
    "\n",
    "            if cell_output is None:  # time == 0\n",
    "                next_cell_state = encoder_final_state#cell.zero_state(batch_size, tf.float32)\n",
    "                #inp=tf.zeros([batch_size, trg_emb_size+num_units], dtype=tf.float32)\n",
    "                #print(\"if\",next_cell_state)\n",
    "                #print(\"if \",inputs)\n",
    "                inp=initialize\n",
    "\n",
    "            else:\n",
    "                #print(\"a=\",cell_output)\n",
    "                next_cell_state = cell_state\n",
    "                #print(\"else\",next_cell_state)\n",
    "              \n",
    "                inp=tf.nn.sigmoid(tf.add(tf.matmul(cell_output,dense_w),dense_b))\n",
    "                #print(\"temp\",temp)\n",
    "\n",
    "\n",
    "                print(\"cell_output\",cell_output)\n",
    "\n",
    "                print(batch_size)\n",
    "                \"\"\"\"\n",
    "                temp=tf.reshape(cell_output,(batch_size,1,num_units))\n",
    "\n",
    "                temp=tf.multiply(context_vector,temp)\n",
    "\n",
    "                alpha=tf.nn.softmax(tf.reshape(tf.reduce_sum(temp,axis=2),(batch_size,maxtime,1)),axis=1)\n",
    "                print(alpha)\n",
    "                \"\"\"\n",
    "                \n",
    "                \n",
    "\n",
    "                batch,_=tf.unstack(tf.shape(cell_output))\n",
    "                \n",
    "                with tf.variable_scope(\"attention\"):\n",
    "\n",
    "                    ft=tf.multiply(tf.tensordot(context_vector,Ma,axes=[[2],[0]]), tf.reshape(cell_output,(batch,1,num_units,1)))\n",
    "                    ft=tf.reduce_sum(ft,axis=2)\n",
    "\n",
    "                    print(\"ft\",ft)\n",
    "\n",
    "                    #print(\"ones\",tf.concat((tf.multiply(tf.ones((1,max_time,num_units),dtype=tf.float32),tf.reshape(cell_output,(batch,1,num_units))),context_vector),axis=2))\n",
    "                    st=tf.concat((tf.multiply(tf.ones((1,maxrword,num_units),dtype=tf.float32),tf.reshape(cell_output,(batch,1,num_units))),context_vector),axis=2)\n",
    "                    print(\"st\",st,tf.reshape(Va,(2*num_units,attention_a,1)))\n",
    "                    print(tf.tensordot(st,tf.reshape(Va,(2*num_units,attention_a,1)),axes=[[2],[0]]))\n",
    "                    #st=tf.concat((tf.multiply(tf.ones((1,max_time,num_units),dtype=tf.float32),tf.reshape(cell_output,(batch,1,num_units))),context_vector),axis=2)\n",
    "                    st=tf.reshape(tf.tensordot(st,tf.reshape(Va,(2*num_units,attention_a,1)),axes=[[2],[0]]),(batch,maxrword,attention_a))\n",
    "\n",
    "                    print(\"st\",st)\n",
    "\n",
    "                    tt=tf.reshape(ba,(1,1,attention_a))\n",
    "\n",
    "                    print(\"tt\",tt)\n",
    "\n",
    "                    alpha=tf.nn.softmax(tf.reduce_sum(tf.multiply(tf.reshape(Ua,(1,1,attention_a)),tf.nn.tanh(tf.add(tf.add(ft,st),tt))),axis=2))\n",
    "                    print(\"a\",alpha)\n",
    "                    alpha=tf.reshape(alpha,(batch,maxrword,1))\n",
    "\n",
    "                    print(\"alpha\",alpha)\n",
    "\n",
    "                    temp=tf.multiply(alpha,context_vector)\n",
    "\n",
    "                    ctx=tf.reduce_sum(temp,axis=1)\n",
    "\n",
    "                inp=tf.concat([inp,ctx],axis=1)\n",
    "\n",
    "                print(\"inp\",inp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            emit_output=cell_output\n",
    "                #inp=tf.as.dese(cell_output,20,activation='softmax',name=\"dense\"+(str)(time))\n",
    "                #print(\"else \",inputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(\"emit\",emit_output)\n",
    "            elements_finished = (time >= trg_seq_length)\n",
    "            print(\"elements_finished\",elements_finished)\n",
    "            finished = tf.reduce_all(elements_finished)\n",
    "            #inp=tf.layers.dense(cell_output,20,activation='softmax')\n",
    "            print(batch_size)\n",
    "            next_input=inp\n",
    "            \"\"\"next_input = tf.cond(\n",
    "              finished,\n",
    "              lambda: initialize,\n",
    "              lambda: inp)\"\"\"\n",
    "            next_loop_state = None\n",
    "            print(next_input)\n",
    "            return (elements_finished, next_input, next_cell_state,\n",
    "                  emit_output, next_loop_state)\n",
    "\n",
    "\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            decoder_lstm_cell =tf.contrib.rnn.LSTMCell(num_units)\n",
    "            decoder_lstm_net=tf.nn.raw_rnn(decoder_lstm_cell, loop_fn)\n",
    "            print(\"decoder\",decoder_lstm_net)\n",
    "            outputs_ta, final_state, _ = decoder_lstm_net\n",
    "            outputs = outputs_ta.stack()\n",
    "            print(\"outputs=\",outputs)\n",
    "            seq_len,batch,hidden_units=tf.unstack(tf.shape(outputs))\n",
    "            new_out=tf.reshape(outputs,[seq_len*batch,hidden_units])\n",
    "            temp=tf.nn.sigmoid(tf.add(tf.matmul(new_out,dense_w),dense_b))\n",
    "            print(\"temp\",temp)\n",
    "\n",
    "            predicted=tf.transpose(tf.reshape(temp,[seq_len,batch,trg_emb_size]),[1,0,2])\n",
    "            print(\"labels=\",labels)\n",
    "            print(\"predicted=\",predicted)\n",
    "            #cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=predicted))\n",
    "            #print(\"losses=\",tf.losses.softmax_cross_entropy(labels,predicted))\n",
    "            shapepredicted=tf.shape(predicted)\n",
    "            print(\"shape\",tf.shape(labels))\n",
    "            batch,seq_len,vocab=tf.unstack(tf.shape(predicted))\n",
    "            lb=tf.slice(labels,[0,0,0],[batch,seq_len,vocab])\n",
    "\n",
    "\n",
    "        print(\"labels=\",lb)\n",
    "        \n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        #cross_entropy=tf.losses.softmax_cross_entropy(lb,predicted)\n",
    "        mean_square_loss=tf.losses.mean_squared_error(lb,predicted)\n",
    "        print(mean_square_loss)\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(mean_square_loss)\n",
    "\n",
    "        #correct_prediction = tf.equal(tf.argmax(predicted, 2), tf.argmax(lb, 2))\n",
    "        #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        #print(\"ac\",accuracy)\n",
    "       \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing summary on tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer=tf.summary.FileWriter('models/',g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "mean square loss for batch 1 0.3858786\n",
      "mean square loss for batch 2 0.3858786\n",
      "epoch  1\n",
      "mean square loss for batch 1 0.38195533\n",
      "mean square loss for batch 2 0.38195533\n",
      "epoch  2\n",
      "mean square loss for batch 1 0.37807828\n",
      "mean square loss for batch 2 0.37807828\n",
      "epoch  3\n",
      "mean square loss for batch 1 0.37425688\n",
      "mean square loss for batch 2 0.37425688\n",
      "epoch  4\n",
      "mean square loss for batch 1 0.3705012\n",
      "mean square loss for batch 2 0.3705012\n",
      "epoch  5\n",
      "mean square loss for batch 1 0.36682117\n",
      "mean square loss for batch 2 0.36682117\n",
      "epoch  6\n",
      "mean square loss for batch 1 0.363226\n",
      "mean square loss for batch 2 0.363226\n",
      "epoch  7\n",
      "mean square loss for batch 1 0.35972324\n",
      "mean square loss for batch 2 0.35972324\n",
      "epoch  8\n",
      "mean square loss for batch 1 0.35631835\n",
      "mean square loss for batch 2 0.35631835\n",
      "epoch  9\n",
      "mean square loss for batch 1 0.35301453\n",
      "mean square loss for batch 2 0.35301453\n",
      "epoch  10\n",
      "mean square loss for batch 1 0.34981325\n",
      "mean square loss for batch 2 0.34981325\n",
      "epoch  11\n",
      "mean square loss for batch 1 0.34671453\n",
      "mean square loss for batch 2 0.34671453\n",
      "epoch  12\n",
      "mean square loss for batch 1 0.3437167\n",
      "mean square loss for batch 2 0.3437167\n",
      "epoch  13\n",
      "mean square loss for batch 1 0.3408178\n",
      "mean square loss for batch 2 0.3408178\n",
      "epoch  14\n",
      "mean square loss for batch 1 0.33801484\n",
      "mean square loss for batch 2 0.33801484\n",
      "epoch  15\n",
      "mean square loss for batch 1 0.33530515\n",
      "mean square loss for batch 2 0.33530515\n",
      "epoch  16\n",
      "mean square loss for batch 1 0.33268613\n",
      "mean square loss for batch 2 0.33268613\n",
      "epoch  17\n",
      "mean square loss for batch 1 0.33015537\n",
      "mean square loss for batch 2 0.33015537\n",
      "epoch  18\n",
      "mean square loss for batch 1 0.32771048\n",
      "mean square loss for batch 2 0.32771048\n",
      "epoch  19\n",
      "mean square loss for batch 1 0.3253492\n",
      "mean square loss for batch 2 0.3253492\n",
      "epoch  20\n",
      "mean square loss for batch 1 0.32306907\n",
      "mean square loss for batch 2 0.32306907\n",
      "epoch  21\n",
      "mean square loss for batch 1 0.32086703\n",
      "mean square loss for batch 2 0.32086703\n",
      "epoch  22\n",
      "mean square loss for batch 1 0.3187401\n",
      "mean square loss for batch 2 0.3187401\n",
      "epoch  23\n",
      "mean square loss for batch 1 0.31668475\n",
      "mean square loss for batch 2 0.31668475\n",
      "epoch  24\n",
      "mean square loss for batch 1 0.3146973\n",
      "mean square loss for batch 2 0.3146973\n",
      "epoch  25\n",
      "mean square loss for batch 1 0.31277385\n",
      "mean square loss for batch 2 0.31277385\n",
      "epoch  26\n",
      "mean square loss for batch 1 0.31091043\n",
      "mean square loss for batch 2 0.31091043\n",
      "epoch  27\n",
      "mean square loss for batch 1 0.30910325\n",
      "mean square loss for batch 2 0.30910325\n",
      "epoch  28\n",
      "mean square loss for batch 1 0.30734852\n",
      "mean square loss for batch 2 0.30734852\n",
      "epoch  29\n",
      "mean square loss for batch 1 0.30564246\n",
      "mean square loss for batch 2 0.30564246\n",
      "epoch  30\n",
      "mean square loss for batch 1 0.30398178\n",
      "mean square loss for batch 2 0.30398178\n",
      "epoch  31\n",
      "mean square loss for batch 1 0.30236313\n",
      "mean square loss for batch 2 0.30236313\n",
      "epoch  32\n",
      "mean square loss for batch 1 0.30078363\n",
      "mean square loss for batch 2 0.30078363\n",
      "epoch  33\n",
      "mean square loss for batch 1 0.29924065\n",
      "mean square loss for batch 2 0.29924065\n",
      "epoch  34\n",
      "mean square loss for batch 1 0.29773176\n",
      "mean square loss for batch 2 0.29773176\n",
      "epoch  35\n",
      "mean square loss for batch 1 0.29625484\n",
      "mean square loss for batch 2 0.29625484\n",
      "epoch  36\n",
      "mean square loss for batch 1 0.29480818\n",
      "mean square loss for batch 2 0.29480818\n",
      "epoch  37\n",
      "mean square loss for batch 1 0.2933902\n",
      "mean square loss for batch 2 0.2933902\n",
      "epoch  38\n",
      "mean square loss for batch 1 0.2919999\n",
      "mean square loss for batch 2 0.2919999\n",
      "epoch  39\n",
      "mean square loss for batch 1 0.29063612\n",
      "mean square loss for batch 2 0.29063612\n",
      "epoch  40\n",
      "mean square loss for batch 1 0.28929833\n",
      "mean square loss for batch 2 0.28929833\n",
      "epoch  41\n",
      "mean square loss for batch 1 0.28798604\n",
      "mean square loss for batch 2 0.28798604\n",
      "epoch  42\n",
      "mean square loss for batch 1 0.28669912\n",
      "mean square loss for batch 2 0.28669912\n",
      "epoch  43\n",
      "mean square loss for batch 1 0.28543738\n",
      "mean square loss for batch 2 0.28543738\n",
      "epoch  44\n",
      "mean square loss for batch 1 0.28420094\n",
      "mean square loss for batch 2 0.28420094\n",
      "epoch  45\n",
      "mean square loss for batch 1 0.28298983\n",
      "mean square loss for batch 2 0.28298983\n",
      "epoch  46\n",
      "mean square loss for batch 1 0.28180432\n",
      "mean square loss for batch 2 0.28180432\n",
      "epoch  47\n",
      "mean square loss for batch 1 0.28064424\n",
      "mean square loss for batch 2 0.28064424\n",
      "epoch  48\n",
      "mean square loss for batch 1 0.2795096\n",
      "mean square loss for batch 2 0.2795096\n",
      "epoch  49\n",
      "mean square loss for batch 1 0.27840015\n",
      "mean square loss for batch 2 0.27840015\n",
      "epoch  50\n",
      "mean square loss for batch 1 0.27731556\n",
      "mean square loss for batch 2 0.27731556\n",
      "epoch  51\n",
      "mean square loss for batch 1 0.27625525\n",
      "mean square loss for batch 2 0.27625525\n",
      "epoch  52\n",
      "mean square loss for batch 1 0.2752185\n",
      "mean square loss for batch 2 0.2752185\n",
      "epoch  53\n",
      "mean square loss for batch 1 0.27420434\n",
      "mean square loss for batch 2 0.27420434\n",
      "epoch  54\n",
      "mean square loss for batch 1 0.2732118\n",
      "mean square loss for batch 2 0.2732118\n",
      "epoch  55\n",
      "mean square loss for batch 1 0.2722397\n",
      "mean square loss for batch 2 0.2722397\n",
      "epoch  56\n",
      "mean square loss for batch 1 0.27128682\n",
      "mean square loss for batch 2 0.27128682\n",
      "epoch  57\n",
      "mean square loss for batch 1 0.2703517\n",
      "mean square loss for batch 2 0.2703517\n",
      "epoch  58\n",
      "mean square loss for batch 1 0.26943296\n",
      "mean square loss for batch 2 0.26943296\n",
      "epoch  59\n",
      "mean square loss for batch 1 0.26852912\n",
      "mean square loss for batch 2 0.26852912\n",
      "epoch  60\n",
      "mean square loss for batch 1 0.26763868\n",
      "mean square loss for batch 2 0.26763868\n",
      "epoch  61\n",
      "mean square loss for batch 1 0.26676014\n",
      "mean square loss for batch 2 0.26676014\n",
      "epoch  62\n",
      "mean square loss for batch 1 0.265892\n",
      "mean square loss for batch 2 0.265892\n",
      "epoch  63\n",
      "mean square loss for batch 1 0.26503262\n",
      "mean square loss for batch 2 0.26503262\n",
      "epoch  64\n",
      "mean square loss for batch 1 0.26418054\n",
      "mean square loss for batch 2 0.26418054\n",
      "epoch  65\n",
      "mean square loss for batch 1 0.26333416\n",
      "mean square loss for batch 2 0.26333416\n",
      "epoch  66\n",
      "mean square loss for batch 1 0.26249212\n",
      "mean square loss for batch 2 0.26249212\n",
      "epoch  67\n",
      "mean square loss for batch 1 0.26165307\n",
      "mean square loss for batch 2 0.26165307\n",
      "epoch  68\n",
      "mean square loss for batch 1 0.2608159\n",
      "mean square loss for batch 2 0.2608159\n",
      "epoch  69\n",
      "mean square loss for batch 1 0.25997978\n",
      "mean square loss for batch 2 0.25997978\n",
      "epoch  70\n",
      "mean square loss for batch 1 0.25914446\n",
      "mean square loss for batch 2 0.25914446\n",
      "epoch  71\n",
      "mean square loss for batch 1 0.25831017\n",
      "mean square loss for batch 2 0.25831017\n",
      "epoch  72\n",
      "mean square loss for batch 1 0.25747812\n",
      "mean square loss for batch 2 0.25747812\n",
      "epoch  73\n",
      "mean square loss for batch 1 0.25665006\n",
      "mean square loss for batch 2 0.25665006\n",
      "epoch  74\n",
      "mean square loss for batch 1 0.25582847\n",
      "mean square loss for batch 2 0.25582847\n",
      "epoch  75\n",
      "mean square loss for batch 1 0.25501594\n",
      "mean square loss for batch 2 0.25501594\n",
      "epoch  76\n",
      "mean square loss for batch 1 0.25421456\n",
      "mean square loss for batch 2 0.25421456\n",
      "epoch  77\n",
      "mean square loss for batch 1 0.2534253\n",
      "mean square loss for batch 2 0.2534253\n",
      "epoch  78\n",
      "mean square loss for batch 1 0.25264812\n",
      "mean square loss for batch 2 0.25264812\n",
      "epoch  79\n",
      "mean square loss for batch 1 0.25188208\n",
      "mean square loss for batch 2 0.25188208\n",
      "epoch  80\n",
      "mean square loss for batch 1 0.25112635\n",
      "mean square loss for batch 2 0.25112635\n",
      "epoch  81\n",
      "mean square loss for batch 1 0.25038022\n",
      "mean square loss for batch 2 0.25038022\n",
      "epoch  82\n",
      "mean square loss for batch 1 0.24964313\n",
      "mean square loss for batch 2 0.24964313\n",
      "epoch  83\n",
      "mean square loss for batch 1 0.24891445\n",
      "mean square loss for batch 2 0.24891445\n",
      "epoch  84\n",
      "mean square loss for batch 1 0.24819344\n",
      "mean square loss for batch 2 0.24819344\n",
      "epoch  85\n",
      "mean square loss for batch 1 0.24747938\n",
      "mean square loss for batch 2 0.24747938\n",
      "epoch  86\n",
      "mean square loss for batch 1 0.24677148\n",
      "mean square loss for batch 2 0.24677148\n",
      "epoch  87\n",
      "mean square loss for batch 1 0.24606912\n",
      "mean square loss for batch 2 0.24606912\n",
      "epoch  88\n",
      "mean square loss for batch 1 0.2453717\n",
      "mean square loss for batch 2 0.2453717\n",
      "epoch  89\n",
      "mean square loss for batch 1 0.24467865\n",
      "mean square loss for batch 2 0.24467865\n",
      "epoch  90\n",
      "mean square loss for batch 1 0.24398944\n",
      "mean square loss for batch 2 0.24398944\n",
      "epoch  91\n",
      "mean square loss for batch 1 0.24330333\n",
      "mean square loss for batch 2 0.24330333\n",
      "epoch  92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square loss for batch 1 0.24261987\n",
      "mean square loss for batch 2 0.24261987\n",
      "epoch  93\n",
      "mean square loss for batch 1 0.24193858\n",
      "mean square loss for batch 2 0.24193858\n",
      "epoch  94\n",
      "mean square loss for batch 1 0.24125911\n",
      "mean square loss for batch 2 0.24125911\n",
      "epoch  95\n",
      "mean square loss for batch 1 0.24058136\n",
      "mean square loss for batch 2 0.24058136\n",
      "epoch  96\n",
      "mean square loss for batch 1 0.23990518\n",
      "mean square loss for batch 2 0.23990518\n",
      "epoch  97\n",
      "mean square loss for batch 1 0.23923053\n",
      "mean square loss for batch 2 0.23923053\n",
      "epoch  98\n",
      "mean square loss for batch 1 0.23855737\n",
      "mean square loss for batch 2 0.23855737\n",
      "epoch  99\n",
      "mean square loss for batch 1 0.23788571\n",
      "mean square loss for batch 2 0.23788571\n"
     ]
    }
   ],
   "source": [
    "pred=\"\"\n",
    "with g.as_default():\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            bt=543\n",
    "            epochs=100\n",
    "            for k in range(epochs):\n",
    "                print(\"epoch \",k)\n",
    "                sess.run(train_step,{initialize:np.zeros((bt,trg_emb_size+num_units)),inputsq:qs[0:bt],inputsr:rs[0:bt],labels:fs[0:bt],src_seq_length:rsqlen[0:bt],trg_seq_length:fsqlen[0:bt]})\n",
    "                \n",
    "                sess.run(train_step,{initialize:np.zeros((bt,trg_emb_size+num_units)),inputsq:qs[bt:],inputsr:rs[bt:],labels:fs[bt:],src_seq_length:rsqlen[bt:],trg_seq_length:fsqlen[bt:]})\n",
    "                m=sess.run(mean_square_loss,{initialize:np.ones((bt,trg_emb_size+num_units)),inputsq:qs[0:bt],inputsr:rs[0:bt],labels:fs[0:bt],src_seq_length:rsqlen[0:bt],trg_seq_length:fsqlen[0:bt]})\n",
    "                print(\"mean square loss for batch 1\",m)\n",
    "                sess.run(mean_square_loss,{initialize:np.ones((bt,trg_emb_size+num_units)),inputsq:qs[bt:],inputsr:rs[bt:],labels:fs[bt:],src_seq_length:rsqlen[bt:],trg_seq_length:fsqlen[bt:]})\n",
    "                print(\"mean square loss for batch 2\",m)\n",
    "                \n",
    "                \n",
    "                \n",
    "            pred=sess.run(predicted,{initialize:np.ones((bt,trg_emb_size+num_units)),inputsq:qs[0:bt],inputsr:rs[0:bt],labels:fs[0:bt],src_seq_length:rsqlen[0:bt],trg_seq_length:fsqlen[0:bt]})\n",
    "            \n",
    "            #print(finals.c.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding euclidean distance between predicted embedding and word to vec vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mispell:\n",
    "    word_vector.pop(i,None)\n",
    "    \n",
    "keys=np.array(list(word_vector.keys()))\n",
    "    \n",
    "disp=[]\n",
    "disa=[]\n",
    "for i in word_vector.keys():\n",
    "    #print(i)\n",
    "   \n",
    "\n",
    "    temp=np.array(word_vector[i]).reshape(1,1,50)\n",
    "\n",
    "    disp.append(np.linalg.norm(temp-pred[0:50],ord=2,axis=2))\n",
    "    disa.append(np.linalg.norm(temp-fs[0:50],ord=2,axis=2))\n",
    "disp=np.array(disp)\n",
    "disa=np.array(disa)\n",
    "dp=np.argmin(disp,axis=0)\n",
    "da=np.argmin(disa,axis=0)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['importantly', 'importantly', 'importantly', 'importantly',\n",
       "       'luckily', 'luckily', 'luckily', 'luckily', 'luckily', 'luckily',\n",
       "       'luckily', 'luckily', 'luckily', 'luckily', 'luckily', 'luckily',\n",
       "       'luckily', 'luckily', 'luckily', 'luckily', 'luckily', 'luckily',\n",
       "       'luckily', 'luckily', 'luckily', 'luckily', 'luckily', 'luckily',\n",
       "       'luckily', 'luckily', 'luckily', 'luckily', 'luckily', 'luckily',\n",
       "       'luckily', 'luckily', 'luckily', 'luckily', 'luckily', 'luckily',\n",
       "       'luckily', 'luckily', 'luckily', 'luckily', 'luckily', 'luckily',\n",
       "       'luckily'], dtype='<U17')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys[dp[16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['why', 'should', 'i', 'hire', 'you', 'emulating', 'emulating',\n",
       "       'emulating', 'emulating', 'emulating', 'emulating', 'emulating',\n",
       "       'emulating', 'emulating', 'emulating', 'emulating', 'emulating',\n",
       "       'emulating', 'emulating', 'emulating', 'emulating', 'emulating',\n",
       "       'emulating', 'emulating', 'emulating', 'emulating', 'emulating',\n",
       "       'emulating', 'emulating', 'emulating', 'emulating', 'emulating',\n",
       "       'emulating', 'emulating', 'emulating', 'emulating', 'emulating',\n",
       "       'emulating', 'emulating', 'emulating', 'emulating', 'emulating',\n",
       "       'emulating', 'emulating', 'emulating', 'emulating', 'emulating',\n",
       "       'emulating', 'emulating', 'emulating'], dtype='<U17')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys[da[16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
