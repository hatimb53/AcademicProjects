{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Algorithm on Iris datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('../../datasets/Assignment_data/Data_Q2/iris.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing on datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical column it into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['species']=data['species'].astype('category').cat.codes\n",
    "data1=pd.get_dummies(data,columns=['species'])\n",
    "data['species']=data['species'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling null by median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns=['sepal_length','sepal_width','petal_length','petal_width','species']\n",
    "\n",
    "for i in columns:\n",
    "    if(np.where(data.isnull()[i]==True)[0].shape!=(0,)):\n",
    "        print(i)\n",
    "        data[i]=data[i].fillna(data[i].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=data.sample(frac=0.8,random_state=200)\n",
    "test=data.drop(train.index)\n",
    "\n",
    "trainy=train['species'].as_matrix()\n",
    "y=trainy\n",
    "trainy=trainy.reshape(trainy.shape[0],1)\n",
    "a=time.clock()\n",
    "#print(train)\n",
    "mean=[]\n",
    "#print(train[train['species']==2].mean().as_matrix())\n",
    "for i in range(0,3):\n",
    "    #print(i)\n",
    "    mean.append(train[train['species']==i].mean().as_matrix())\n",
    "    #print(mean)\n",
    "\n",
    "std=[]\n",
    "for i in range(0,3):\n",
    "    #print(i)\n",
    "    std.append(train[train['species']==i].std().as_matrix())\n",
    "\n",
    "mean=np.array(mean)\n",
    "std=np.array(std)\n",
    "\n",
    "mean=np.delete(mean,mean.shape[1]-1,axis=1)\n",
    "std=np.delete(std,std.shape[1]-1,axis=1)\n",
    "b=time.clock()\n",
    "traintime=b-a\n",
    "\n",
    "trainx=train.drop(['species'],axis=1).as_matrix()\n",
    "\n",
    "testy=test['species'].as_matrix()\n",
    "testx=test.drop(['species'],axis=1).as_matrix()\n",
    "\n",
    "y1=testy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4)\n",
      "Accuracy= 0.9333333333333333\n",
      "training Time= 0\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "t=[]\n",
    "print(testx.shape)\n",
    "x=testx.reshape(testx.shape[0],trainx.shape[1])\n",
    "for i in range(testx.shape[0]):\n",
    "    x=testx[i].reshape(1,trainx.shape[1])\n",
    "    dist = np.linalg.norm(trainx-x,axis=1)\n",
    "    t.append(trainy[np.where(dist==dist.min())[0]][0])\n",
    "t=np.array(t)\n",
    "t=t[:,0]\n",
    "accuracy=np.where(t==testy)[0].shape[0]/testy.shape[0]\n",
    "print(\"Accuracy=\",accuracy)\n",
    "print(\"training Time=\",0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating eucladian distance and apparently classifying points on basis of distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.8333333333333334\n",
      "training time= 0.004152447196304365\n"
     ]
    }
   ],
   "source": [
    "# naive bayes\n",
    "\n",
    "\n",
    "\n",
    "def prob(X,mean,std):\n",
    "   \n",
    "    z=np.square((X-mean)/std)/2\n",
    "    \n",
    "    return np.exp(-z)/(np.sqrt(2*np.pi)*std)\n",
    "\n",
    "\n",
    "p1=np.where(trainy==0)[0].shape[0]/trainy.shape[0]\n",
    "p2=np.where(trainy==1)[0].shape[0]/trainy.shape[0]\n",
    "p3=np.where(trainy==2)[0].shape[0]/trainy.shape[0]\n",
    "\n",
    "t=[]\n",
    "for i in range(testx.shape[0]):\n",
    "    q1=prob(testx[i],mean[0],std[0]).prod()\n",
    "    q2=prob(testx[i],mean[1],std[1]).prod()\n",
    "    q3=prob(testx[i],mean[2],std[2]).prod()\n",
    "    t.append(np.argmax([p1*q1,p2*q2,q3*p3]))\n",
    "t=np.array(t)\n",
    "\n",
    "\n",
    "accuracy=np.where(t==testy)[0].shape[0]/testy.shape[0]\n",
    "print(\"Accuracy=\",accuracy)\n",
    "\n",
    "print(\"training time=\",traintime )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the probability using bayes theorem and calculating the accuracy as well as training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.9\n",
      "training time= 0.1775091238174582\n"
     ]
    }
   ],
   "source": [
    "# using library logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg=LogisticRegression()\n",
    "a=time.clock()\n",
    "lg.fit(trainx,trainy)\n",
    "b=time.clock()\n",
    "t=lg.predict(testx)\n",
    "\n",
    "accuracy=np.where(t==testy)[0].shape[0]/testy.shape[0]\n",
    "print(\"Accuracy=\",accuracy)\n",
    "print(\"training time=\",b-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical data into one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 3)\n"
     ]
    }
   ],
   "source": [
    "train=data1.sample(frac=0.8,random_state=200)\n",
    "test=data1.drop(train.index)\n",
    "\n",
    "trainy=train[['species_0','species_1','species_2']].as_matrix()\n",
    "\n",
    "trainx=train.drop(['species_0','species_1','species_2'],axis=1).as_matrix()\n",
    "\n",
    "testy=test[['species_0','species_1','species_2']].as_matrix()\n",
    "testx=test.drop(['species_0','species_1','species_2'],axis=1).as_matrix()\n",
    "print(trainy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss and Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.8333333333333334\n",
      "training time= 0.03195438189965216\n"
     ]
    }
   ],
   "source": [
    "#softmax cross entropy loss\n",
    "\n",
    "W = 0.01 * np.random.randn(trainx.shape[1],3)\n",
    "b = np.zeros((1,3))\n",
    "X=trainx\n",
    "y=y.astype('int64')\n",
    "# some hyperparameters\n",
    "step_size = 1e-0\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "# gradient descent loop\n",
    "num_examples = X.shape[0]\n",
    "\n",
    "a=time.clock()\n",
    "for i in range(200):\n",
    "  \n",
    "  \n",
    "    scores = np.dot(X, W) + b \n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) \n",
    "    corect_logprobs = -np.log(probs[range(num_examples),y])\n",
    "    data_loss = np.sum(corect_logprobs)/num_examples\n",
    "    reg_loss = 0.5*reg*np.sum(W*W)\n",
    "    loss = data_loss + reg_loss\n",
    "    \n",
    "  \n",
    " \n",
    "    dscores = probs\n",
    "    dscores[range(num_examples),y] -= 1\n",
    "    dscores /= num_examples\n",
    "  \n",
    " \n",
    "    dW = np.dot(X.T, dscores)\n",
    "    db = np.sum(dscores, axis=0, keepdims=True)\n",
    "  \n",
    "    dW += reg*W \n",
    "\n",
    "    W += -step_size * dW\n",
    "    b += -step_size * db\n",
    "b=time.clock()\n",
    "scores = np.dot(testx, W) + b \n",
    "exp_scores = np.exp(scores)\n",
    "probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) \n",
    "t=np.argmax(probs,axis=1)\n",
    "\n",
    "accuracy=np.where(t==y1)[0].shape[0]/testy.shape[0]\n",
    "print(\"Accuracy=\",accuracy)\n",
    "print(\"training time=\",b-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Loss by gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.6666666666666666\n",
      "training time= 0.0381433796317765\n"
     ]
    }
   ],
   "source": [
    "#gradient descent\n",
    "\n",
    "\n",
    "W = 0.01 * np.random.randn(trainx.shape[1],3)\n",
    "b = np.zeros((1,3))\n",
    "X=trainx\n",
    "Y=trainy\n",
    "y=y.astype('int64')\n",
    "# some hyperparameters\n",
    "step_size = 1e-0\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "# gradient descent loop\n",
    "num_examples = X.shape[0]\n",
    "a=time.clock()\n",
    "for i in range(1000):\n",
    "  \n",
    "  \n",
    "    scores = np.dot(X, W) + b \n",
    "    probs = 1/(1+np.exp(-scores))\n",
    "    \n",
    "    dW = np.dot(X.T,(probs-Y))/X.shape[0]\n",
    "    db=np.sum(probs-Y,axis=0)/X.shape[0]\n",
    "    \n",
    "    dW += reg*W \n",
    "\n",
    "    W += -step_size * dW\n",
    "    b += -step_size * db\n",
    "\n",
    "b=time.clock()\n",
    "scores = np.dot(testx, W) + b \n",
    "exp_scores = np.exp(scores)\n",
    "\n",
    "probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) \n",
    "t=np.argmax(probs,axis=1)\n",
    "\n",
    "\n",
    "accuracy=np.where(t==y1)[0].shape[0]/testy.shape[0]\n",
    "print(\"Accuracy=\",accuracy)\n",
    "print(\"training time=\",b-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newtons Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.4\n",
      "training time= 0.0006714813842449985\n"
     ]
    }
   ],
   "source": [
    "# Newtons method\n",
    "\n",
    "y=y.astype('int64')\n",
    "\n",
    "\n",
    "\n",
    "X=np.concatenate((trainx,np.ones((X.shape[0],1))),axis=1)\n",
    "Y=trainy\n",
    "\n",
    "W = 0.01 * np.random.randn(X.shape[1],Y.shape[1])\n",
    " \n",
    "q=np.zeros(X.shape[0])\n",
    "a=time.clock()\n",
    "\n",
    "scores = np.dot(X, W)\n",
    "probs = 1/(1+np.exp(-scores))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    q[i]=probs[i,y[i]]\n",
    "\n",
    "dW = np.dot(X.T,(probs-Y))/X.shape[0]\n",
    "\n",
    "\n",
    "H=np.linalg.inv(np.dot(np.dot(X.T,np.diag((q*(1-q)))),X))\n",
    "\n",
    "W += np.dot(H,dW)\n",
    "   \n",
    "b=time.clock()\n",
    "xt=np.concatenate((testx,np.ones((testx.shape[0],1))),axis=1)\n",
    "scores = np.dot(xt, W) \n",
    "probs = 1/(1+np.exp(-scores))\n",
    "\n",
    "t=np.argmax(probs,axis=1)\n",
    "\n",
    "\n",
    "accuracy=np.where(t==y1)[0].shape[0]/testy.shape[0]\n",
    "print(\"Accuracy=\",accuracy)\n",
    "\n",
    "print(\"training time=\",b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
